{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f728c4-c8e8-444b-b894-c87000295313",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c77dc-65d2-41c4-8c8c-c301bc59fa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speech content decode\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from plotting_utils import plot_fncs, color_pals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e963f5-38ca-46a7-9384-4176ed25c9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c8ab6b-313c-4f67-8d25-7a166c612b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as stat_package\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import sem\n",
    "import logging\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7808d6-ab70-4c7b-9d09-4989312cbb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_path}/model_ablation_REVISE.pkl','rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbb4e32-2ece-42ca-90dd-9ad7abc37f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_path}/read_dfs.pkl','rb') as f:\n",
    "    df_read = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447400c4-499f-4f87-b4d4-6388d9480627",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_path}/window_sals.pkl','rb') as f:\n",
    "    window_sals = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde2ffab-2bd2-4d62-baaf-4c521fa94414",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_path}/sample_read_erps.pkl','rb') as f:\n",
    "    erps = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff76e8c7-2473-491a-b21b-a855f1fa892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter1d\n",
    "erps = [gaussian_filter1d(erp,4,axis=1) for erp in erps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbe840a-548c-4015-8c13-461e795d7b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{data_path}/function_resp_df.pkl','rb') as f:\n",
    "    df_activations = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0020d41-05fa-4b35-a9f5-739344fdbffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set plot params \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "# mpl.rcParams['font.sans-serif'] = ['Arial']\n",
    "plt.rcParams.update({'font.size': 6})\n",
    "plt.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02e222c-6d25-4dba-937c-ab52ec9ed46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gimutil.configuration import config\n",
    "# from gimutil.visualization import plotting_tools\n",
    "import matplotlib.pyplot as plt\n",
    "lw = 0.5\n",
    "    \n",
    "        \n",
    "# Computes and plots the dendrogram\n",
    "import seaborn as sns\n",
    "import matplotlib.font_manager\n",
    "import matplotlib as mpl\n",
    "from statannot import add_stat_annotation\n",
    "\n",
    "region_pal = color_pals.regions\n",
    "region_pal_dict = color_pals.region_dict\n",
    "b3_gate_pal = region_pal.copy()\n",
    "b3_gate_pal = b3_gate_pal[:3]\n",
    "b3_gate_pal.append('#4F4E4C')\n",
    "b3_gate_order=['temporal','precentral','postcentral','all']\n",
    "\n",
    "b1_gate_pal = region_pal.copy()\n",
    "b1_gate_pal = list(np.array(b1_gate_pal)[[1,2,3]])\n",
    "b1_gate_pal.append('#4F4E4C')\n",
    "b1_gate_order =['precentral','postcentral','frontal','all']\n",
    "\n",
    "\n",
    "distractor_pal = list(np.array(color_pals.distractors)[[0,-1]])\n",
    "distractor_order = ['Attempted speech','Listen']\n",
    "base_pal = sns.color_palette('deep').as_hex()\n",
    "palette = ['#4F4E4C',base_pal[0],base_pal[1],base_pal[2]]\n",
    "\n",
    "# Specifies plot parameters\n",
    "rows = {\n",
    "    'third_start' : 0,\n",
    "    'third_stop' : 150,\n",
    "    'fourth_start' : 250,\n",
    "    'fourth_stop' : 400,\n",
    "    'fifth_start' : 500,\n",
    "    'fifth_stop' : 700,\n",
    "    'total'      : 700,\n",
    "}\n",
    "\n",
    "cols = {\n",
    "    'erp1_start' : 0,\n",
    "    'erp1_stop' : 150,\n",
    "    'erp2_start' : 160,#200,\n",
    "    'erp2_stop' : 310,\n",
    "    'erp3_start' : 320,\n",
    "    'erp3_stop' : 470,\n",
    "    'salsquant_start' : 530,\n",
    "    'salsquant_stop' : 800,\n",
    "    'readquant1_start': 400,\n",
    "    'readquant1_stop' : 550,\n",
    "    'readquant2_start' : 650,\n",
    "    'readquant2_stop' : 800,\n",
    "    'ablation_start' : 100,\n",
    "    'ablation_stop' : 700,\n",
    "    'total'      : 800\n",
    "}\n",
    "all_panel_params = {\n",
    "    'erp1' : {'row_and_col_spec' : ('third', 'erp1')},\n",
    "    'erp2' : {'row_and_col_spec' : ('third', 'erp2')},\n",
    "    'readquant1' : {'row_and_col_spec' : ('third', 'readquant1')},\n",
    "    'readquant2' : {'row_and_col_spec' : ('third', 'readquant2')},\n",
    "    'early_sal' : {'row_and_col_spec' : ('fourth', 'erp1')},\n",
    "    'mid_sal' : {'row_and_col_spec' : ('fourth', 'erp2')},\n",
    "    'late_sal' : {'row_and_col_spec' : ('fourth', 'erp3')},\n",
    "    'readingsal' : {'row_and_col_spec' : ('fourth', 'salsquant')},\n",
    "    'ablation' : {'row_and_col_spec' : ('fifth', 'ablation')},\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "dims = np.array([cols['total'],rows['total']])/np.max([rows['total'],cols['total']])\n",
    "scale = 8.17\n",
    "# Creates the plot\n",
    "fig, axs = plot_fncs.setup_figure(\n",
    "    all_panel_params=all_panel_params, row_specs=rows, col_specs=cols,\n",
    "    figsize=scale*dims #15,12\n",
    ")\n",
    "\n",
    "\n",
    "alt_pal = sns.color_palette('bone_r').as_hex()\n",
    "alt_pal = [alt_pal[-1],alt_pal[3],alt_pal[0]]\n",
    "\n",
    "ax = axs['erp1']\n",
    "ax = plot_fncs.plot_erps(erps,0, np.linspace(-2, 2, num=erps[0].shape[1]), ax,do_axes=True,colors=alt_pal,legends=None)    \n",
    "ax.set_title('Strong language pref.')\n",
    "sns.despine(ax=ax,offset={'left': 5,'bottom': 5})\n",
    "ax.set_xlim([-2,2])\n",
    "ax = axs['erp2']\n",
    "ax = plot_fncs.plot_erps(erps,1, np.linspace(-2, 2, num=erps[0].shape[1]), ax,do_axes=True,colors=alt_pal,\n",
    "                         legends=['Words (ex: India)','Sentences (ex: Nobody likes snakes)','False fonts (ex: ƋΨΞƩΔ)'])    \n",
    "ax.set(yticks=[],ylabel='')   \n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.set_title('Weak language pref.')\n",
    "ax.set_xlim([-2,2])\n",
    "sns.despine(ax=ax,offset={'bottom': 5},left=True)\n",
    "ax.legend(fontsize=6,frameon=False)\n",
    "\n",
    "### PANEL: Quantify reading against false\n",
    "ax = axs['readquant1']\n",
    "\n",
    "ax_lim = [-0.2,0.5]\n",
    "ax_ticks = [-0.2,0,0.5]\n",
    "g = sns.scatterplot(ax=ax,data=df_read[(df_read.p < 0.05) & (df_read.read_max >0)],y='read_max',x='read_false',clip_on=False,\n",
    "               color=palette[0],alpha=0.4,style='patient',s=15)\n",
    "g.legend(frameon=False)\n",
    "ax.set(ylim=ax_lim,xlim=ax_lim,xticks=ax_ticks,yticks=ax_ticks,\n",
    "       ylabel='HGA reading words',xlabel='HGA reading false strings')\n",
    "ax.plot(ax_lim,ax_lim,color='k',linestyle='--')\n",
    "sns.despine(ax=ax,offset=5)\n",
    "\n",
    "from scipy.stats import wilcoxon\n",
    "print(wilcoxon(df_read[df_read.p < 0.05].read_max.values,df_read[df_read.p < 0.05].read_false.values))\n",
    "\n",
    "### PANEL: Quantify reading against sentences\n",
    "ax = axs['readquant2']\n",
    "ax_lim = [0,0.8]\n",
    "ax_ticks = [0,0.4,0.8]\n",
    "sns.scatterplot(ax=ax,data=df_read[(df_read.p < 0.05) & (df_read.read_max >0)],y='read_sent',x='read_max',clip_on=False,\n",
    "               color=palette[0],alpha=0.4,style='patient',legend=None,s=15)\n",
    "ax.set(ylim=ax_lim,xlim=ax_lim,xticks=ax_ticks,yticks=ax_ticks,\n",
    "       xlabel='HGA reading words',ylabel='HGA reading sentences')\n",
    "ax.plot(ax_lim,ax_lim,color='k',linestyle='--')\n",
    "sns.despine(ax=ax,offset=5)\n",
    "print(wilcoxon(df_read[df_read.p < 0.05].read_sent.values,df_read[df_read.p < 0.05].read_max.values))\n",
    "\n",
    "\n",
    "\n",
    "with open(f'{data_path}/b3_electrode_anatomical_localizations.pkl','rb') as f:\n",
    "    anat = pickle.load(f)\n",
    "anat[(anat == 'superiortemporal') | (anat == 'middletemporal')] = 'temporal lobe'\n",
    "anat[(anat == 'caudalmiddlefrontal') | (anat == 'parsopercularis')] = 'precentral'\n",
    "anat[(anat == 'supramarginal')] = 'postcentral' \n",
    "\n",
    "tops = []\n",
    "\n",
    "b3_xlims = [205,515] #310\n",
    "b3_ylims = [100,525] #425\n",
    "\n",
    "### PANEL: Brain plots of early, mid, late sals\n",
    "max_size = 20\n",
    "ax = axs['early_sal'] \n",
    "plot_fncs.plot_vals_on_brain(window_sals[0],palette[0],fig,ax,data_path,size_max=max_size,size_min=3.,\n",
    "                            region_color=region_pal_dict['precentral'])\n",
    "ax.set(title='Pre go-cue')\n",
    "ax.set(xlim=b3_xlims,ylim=b3_ylims)\n",
    "\n",
    "ax = axs['mid_sal'] \n",
    "plot_fncs.plot_vals_on_brain(window_sals[1],palette[0],fig,ax,data_path,size_max=max_size,size_min=3.,\n",
    "                            region_color=region_pal_dict['precentral'])\n",
    "ax.set(title='Centered on go-cue')\n",
    "ax.set(xlim=b3_xlims,ylim=b3_ylims)\n",
    "\n",
    "ax = axs['late_sal'] \n",
    "plot_fncs.plot_vals_on_brain(window_sals[2],palette[0],fig,ax,data_path,size_max=max_size,size_min=3.,\n",
    "                            region_color=region_pal_dict['precentral'])\n",
    "ax.set(title='After go-cue')\n",
    "ax.set(xlim=b3_xlims,ylim=b3_ylims)\n",
    "\n",
    "d_sals_time = {'sal':[],'region':[],'time':[]}\n",
    "d_sals_time['sal'].extend(window_sals[0])\n",
    "d_sals_time['sal'].extend(window_sals[1])\n",
    "d_sals_time['sal'].extend(window_sals[2])\n",
    "\n",
    "d_sals_time['region'].extend(anat)\n",
    "d_sals_time['region'].extend(anat)\n",
    "d_sals_time['region'].extend(anat)\n",
    "\n",
    "d_sals_time['time'].extend(np.repeat('Pre go-cue',253))\n",
    "d_sals_time['time'].extend(np.repeat('Centered \\non go-cue',253))\n",
    "d_sals_time['time'].extend(np.repeat('After go-cue',253))\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "norm_0 = scaler.fit_transform(np.array(window_sals[0]).reshape(-1,1)).squeeze()\n",
    "norm_1 = scaler.fit_transform(np.array(window_sals[1]).reshape(-1,1)).squeeze()\n",
    "norm_2 = scaler.fit_transform(np.array(window_sals[2]).reshape(-1,1)).squeeze()\n",
    "\n",
    "\n",
    "d_sals_time = {'sal_1':window_sals[0],'sal_2': window_sals[1], 'sal_3': window_sals[2],\n",
    "               'region':anat}\n",
    "d_sals_time = {'sal_1':norm_0,'sal_2': norm_1, 'sal_3': norm_2,\n",
    "               'region':anat}\n",
    "d_sals_time = pd.DataFrame(d_sals_time)\n",
    "\n",
    "perc_cut = 90\n",
    "keep = ( (d_sals_time.sal_1 >= np.percentile(d_sals_time.sal_1,perc_cut)) | (d_sals_time.sal_2 >= np.percentile(d_sals_time.sal_2,perc_cut))\n",
    "        | (d_sals_time.sal_3 >= np.percentile(d_sals_time.sal_3,perc_cut)) )\n",
    "\n",
    "d_sals_time = d_sals_time[keep]\n",
    "\n",
    "\n",
    "### PANEL: Quant of the saliences over time \n",
    "ax = axs['readingsal']\n",
    "import matplotlib.pyplot as plt\n",
    "panel_f = pd.read_excel(f'{data_path}/fig5_sourcedata.xlsx',engine='openpyxl',sheet_name='Panel_f').iloc[:,1:]\n",
    "\n",
    "# define the electrodes corresponding to each cluster \n",
    "hand_clust = plot_fncs.adjust_elec_inds(panel_f['top_hand']).values\n",
    "lips_clust = plot_fncs.adjust_elec_inds(panel_f['top_lips']).values\n",
    "coronal_clust = plot_fncs.adjust_elec_inds(panel_f['top_coronal']).values\n",
    "\n",
    "artic = []\n",
    "p_val = [] \n",
    "for i, row in d_sals_time.iterrows():\n",
    "    artic.append( i in lips_clust or i in hand_clust or i in coronal_clust ) \n",
    "    percep_stats = df_activations.iloc[i][['read_p','listen_p']]\n",
    "    p_val.append(percep_stats[0] < 0.05 and percep_stats[1] < 0.05)\n",
    "\n",
    "    \n",
    "d_sals_time['artic'] = artic\n",
    "d_sals_time['read_listen'] = p_val\n",
    "sal_vals = np.concatenate( (d_sals_time.sal_1,d_sals_time.sal_2,d_sals_time.sal_3))\n",
    "artic = np.concatenate( (d_sals_time.artic,d_sals_time.artic,d_sals_time.artic) ) \n",
    "read_listen = np.concatenate( (d_sals_time.read_listen,d_sals_time.read_listen,\n",
    "                               d_sals_time.read_listen) ) \n",
    "time_win = np.concatenate( (np.repeat('Pre-go cue',len(d_sals_time.sal_1)),\n",
    "                            np.repeat('Centered on go cue',len(d_sals_time.sal_2)),\n",
    "                            np.repeat('After-go cue',len(d_sals_time.sal_3)) ) )\n",
    "\n",
    "tag = artic.copy()\n",
    "tag[artic] = 'Artic.'\n",
    "tag[read_listen] = 'Multiplexed'\n",
    "\n",
    "d_sals_time_plt = pd.DataFrame({'Time window': time_win, 'Salience': sal_vals,\n",
    "                                'Artic': artic, 'Multiplexed': read_listen})\n",
    "tag = []\n",
    "for i,row in d_sals_time_plt.iterrows():\n",
    "    if(row.Artic):\n",
    "        tag.append('Artic.')\n",
    "    elif(row.Multiplexed):\n",
    "        tag.append('Multiplexed')\n",
    "    else:\n",
    "        tag.append('None')\n",
    "        \n",
    "d_sals_time_plt['Category'] = tag\n",
    "\n",
    "from scipy.stats import ranksums\n",
    "p_val = []\n",
    "box_pairs = []\n",
    "for x_align in ['Pre-go cue','Centered on go cue','After-go cue']:\n",
    "    p_val.append(ranksums(d_sals_time_plt[(d_sals_time_plt['Time window'] == x_align) \n",
    "                             & (d_sals_time_plt['Category'] == 'Artic.')].Salience,\n",
    "             d_sals_time_plt[(d_sals_time_plt['Time window'] == x_align) \n",
    "                             & (d_sals_time_plt['Category'] == 'Multiplexed')].Salience )[1])\n",
    "    box_pairs.append(  ((x_align, 'Multiplexed'), (x_align, 'Artic.')) )\n",
    "\n",
    "for cat in ['Shared','Artic.']:\n",
    "    p_val.append(ranksums(d_sals_time_plt[(d_sals_time_plt['Time window'] == 'Pre-go cue') \n",
    "                             & (d_sals_time_plt['Category'] == cat)].Salience,\n",
    "             d_sals_time_plt[(d_sals_time_plt['Time window'] == 'Centered on go cue') \n",
    "                             & (d_sals_time_plt['Category'] == cat)].Salience )[1])\n",
    "    box_pairs.append(  (('Pre-go cue', cat), ('Centered on go cue', cat)) )    \n",
    "\n",
    "    p_val.append(ranksums(d_sals_time_plt[(d_sals_time_plt['Time window'] == 'Pre-go cue') \n",
    "                             & (d_sals_time_plt['Category'] == cat)].Salience,\n",
    "             d_sals_time_plt[(d_sals_time_plt['Time window'] == 'After-go cue') \n",
    "                             & (d_sals_time_plt['Category'] == cat)].Salience )[1])\n",
    "    box_pairs.append(  (('Pre-go cue', cat), ('After-go cue', cat)) )    \n",
    "    \n",
    "    p_val.append(ranksums(d_sals_time_plt[(d_sals_time_plt['Time window'] == 'After-go cue') \n",
    "                             & (d_sals_time_plt['Category'] == cat)].Salience,\n",
    "             d_sals_time_plt[(d_sals_time_plt['Time window'] == 'Centered on go cue') \n",
    "                             & (d_sals_time_plt['Category'] == cat)].Salience )[1])\n",
    "    box_pairs.append(  (('After-go cue', cat), ('Centered on go cue', cat)) )    \n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "p_val = multipletests(p_val,method='holm')[1]\n",
    "print(len(p_val))\n",
    "box_pairs = [b for b,p in zip(box_pairs,p_val) if p < 0.05]\n",
    "p_val = [p for p in p_val if p < 0.05]\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "pal = []\n",
    "pal.append(sns.color_palette('Set2').as_hex()[0])\n",
    "pal.append(sns.color_palette('Set2').as_hex()[2])\n",
    "\n",
    "g = sns.boxplot(ax=ax,data=d_sals_time_plt, x='Time window', y='Salience', hue='Category',\n",
    "           hue_order=['Multiplexed','Artic.'],palette=pal,boxprops=dict(alpha=0.8),linewidth=lw) #'binary'\n",
    "add_stat_annotation(ax, data=d_sals_time_plt,x='Time window', y='Salience', hue='Category',\n",
    "                    box_pairs=box_pairs, hue_order=['Multiplexed','Artic.'],\n",
    "                    test=None, loc='outside', verbose=2,pvalues=p_val,perform_stat_test=False,\n",
    "                    text_offset=0.05,line_offset_to_box=0)\n",
    "\n",
    "\n",
    "ax.set(xticks=[0,1,2],xticklabels=['Pre go-cue','Centered \\non go-cue','After go-cue'],ylim=[0,1],yticks=[0,0.5,1])\n",
    "ax.set(ylabel='Elec. contribution (A.U.)',xlabel='')\n",
    "\n",
    "# ax.legend(bbox_to_anchor=(0.4,0.7),ncol=1,frameon=False)\n",
    "h, _ = ax.get_legend_handles_labels()\n",
    "ax.legend(h, ['Shared', 'Artic.'], bbox_to_anchor=(0.4,0.7),ncol=1,frameon=False);\n",
    "    \n",
    "sns.despine(ax=ax,offset=5,bottom=True)\n",
    "# ax.spines['bottom'].set_visible(False)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "plt.setp(ax.collections, clip_on=False)\n",
    "plt.setp(ax.lines, clip_on=False, zorder=5)\n",
    "\n",
    "###########\n",
    "\n",
    "ax = axs['ablation']\n",
    "wins = ['200.0_600.0','400.0_800.0','600.0_1000.0']\n",
    "model_names = ['Pre go-cue', 'Centered on go-cue','After go-cue']\n",
    "from scipy.stats import ranksums \n",
    "ps = []\n",
    "box_pairs = []\n",
    "for win in model_names:\n",
    "    df_ = df[df.win == win]\n",
    "    ps.append(ranksums(df_[df_.model == 'All elecs.'].acc,df_[df_.model == 'No artic. elecs.'].acc).pvalue)\n",
    "    box_pairs.append( ((win,'All elecs.'), (win,'No artic. elecs.')))\n",
    "    \n",
    "    ps.append(ranksums(df_[df_.model == 'All elecs.'].acc,df_[df_.model == 'No multiplexed elecs.'].acc).pvalue)\n",
    "    box_pairs.append( ((win,'All elecs.'), (win,'No multiplexed elecs.')))\n",
    "\n",
    "    ps.append(ranksums(df_[df_.model == 'No multiplexed elecs.'].acc,df_[df_.model == 'No artic. elecs.'].acc).pvalue)\n",
    "    box_pairs.append( ((win,'No artic. elecs.'), (win,'No multiplexed elecs.')))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "from statsmodels.stats.multitest import multipletests\n",
    "ps = multipletests(ps,method='holm')[1]\n",
    "new_ps, new_bps = [],[]\n",
    "for p,b in zip(ps,box_pairs):\n",
    "    if p < 0.05:\n",
    "        new_ps.append(p)\n",
    "        new_bps.append(b)\n",
    "\n",
    "import seaborn as sns\n",
    "from statannot import add_stat_annotation\n",
    "\n",
    "pal = [sns.color_palette('binary')[3]]\n",
    "pal.append(sns.color_palette('Set2').as_hex()[0])\n",
    "pal.append(sns.color_palette('Set2').as_hex()[2])\n",
    "\n",
    "sns.boxplot(data=df,x='win',hue='model',y='acc',ax=ax,palette=pal,linewidth=lw)\n",
    "\n",
    "\n",
    "add_stat_annotation(ax, data=df,x='win',hue='model',y='acc',\n",
    "                    box_pairs=new_bps, hue_order=['All elecs.','No multiplexed elecs.',\n",
    "                                                    'No artic. elecs.'],\n",
    "                    test=None, loc='outside', verbose=2,pvalues=new_ps,perform_stat_test=False)\n",
    "ax.axhline(10,color='k',linestyle='--')\n",
    "\n",
    "# ax.legend(frameon=False,title='')\n",
    "h, _ = ax.get_legend_handles_labels()\n",
    "ax.legend(h, ['All elecs.','No shared elecs.','No artic. elecs.'], bbox_to_anchor=(0.4,0.7),ncol=1,frameon=False);\n",
    "\n",
    "ax.set(xlabel='',ylabel='Classification accuracy (%)',yticks=[0,50,100],ylim=[0,100])\n",
    "sns.despine(ax=ax,bottom=True,offset=5)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "\n",
    "\n",
    "pad_top = 100\n",
    "axs['erp1'].annotate('A',(-40, pad_top),xycoords='axes points',weight='bold', ha='right',fontsize=9)\n",
    "axs['readquant1'].annotate('B',(-40, pad_top),xycoords='axes points',weight='bold', ha='right',fontsize=9)\n",
    "axs['readquant2'].annotate('C',(-40, pad_top),xycoords='axes points',weight='bold', ha='right',fontsize=9)\n",
    "\n",
    "axs['early_sal'].annotate('D',(-35, pad_top),xycoords='axes points',weight='bold', ha='right',fontsize=9)\n",
    "\n",
    "axs['early_sal'].annotate('Attempted speech \\n contributions', xy=(-0.2, 0.5), rotation=90, \n",
    "            va='center', ha='center',xycoords='axes fraction',fontsize=6)\n",
    "\n",
    "\n",
    "axs['readingsal'].annotate('E',(-35, pad_top),xycoords='axes points',weight='bold', ha='right',fontsize=9)\n",
    "axs['ablation'].annotate('F',(-40, pad_top+25),xycoords='axes points',weight='bold', ha='right',fontsize=9)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7703653e-4a62-4f07-a1e1-ad6669ef434d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distractors",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
